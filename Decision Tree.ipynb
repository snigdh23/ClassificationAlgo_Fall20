{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "class color:\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the code for Report dataset(1) or Demo dataset(2): 1\n",
      "Please enter the file name: data2.txt\n",
      "Please enter Max Depth Value: 100\n",
      "Please enter Min Size Value: 10\n"
     ]
    }
   ],
   "source": [
    "inp = int(input(\"Is the code for Report dataset(1) or Demo dataset(2): \"))\n",
    "file_path = input(\"Please enter the file name: \")\n",
    "if(inp == 1):\n",
    "    max_depth1 = int(input(\"Please enter Max Depth Value: \")) #100\n",
    "    min_size1 = int(input(\"Please enter Min Size Value: \")) #10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurecheck(val):\n",
    "    try:\n",
    "        float(val)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_fold_range(row_count,fold_count):\n",
    "    k_main = []\n",
    "    if(fold_count==1):\n",
    "        step = round(0.23*row_count)\n",
    "        temp = []\n",
    "        temp.append(0)\n",
    "        temp.append(step)\n",
    "        k_main.append(temp)\n",
    "    else:\n",
    "        step = round(row_count / fold_count)\n",
    "        rem = row_count - fold_count * step\n",
    "        p = 0\n",
    "        \n",
    "        for i in range(fold_count):\n",
    "            val_add = 0\n",
    "            if(rem > 0):\n",
    "                val_add = 1\n",
    "            temp = []\n",
    "            temp.append(p)\n",
    "            p = p + step + val_add\n",
    "            temp.append(p)\n",
    "            k_main.append(temp)\n",
    "            rem -= 1\n",
    "        #print(k_main)\n",
    "    return(k_main)\n",
    "\n",
    "\n",
    "def preprocessing_dataset(file_path, inp):\n",
    "    \n",
    "    main_mapping_dict = {}\n",
    "    nominal_features = []\n",
    "    \n",
    "    # Updating the nominal attributes by a number \n",
    "    with open(file_path, 'r') as file1:\n",
    "        data1 = [line.strip().split('\\t') for line in file1]\n",
    "        temp_data = np.asarray(data1)\n",
    "    \n",
    "    (row_count, col_count) = temp_data.shape\n",
    "    for i in range(col_count):\n",
    "        if featurecheck(temp_data[0, i]) == False:\n",
    "            nominal_features.append(i)\n",
    "    \n",
    "    for i in range(len(nominal_features)):\n",
    "        temp_dict = {}\n",
    "        unique_vals = np.unique(temp_data[:, nominal_features[i]]).tolist()\n",
    "        \n",
    "        temp1 = unique_vals\n",
    "        for j in range(len(temp1)):\n",
    "            temp_dict[temp1[j]] = j\n",
    "        main_mapping_dict[i] = temp_dict\n",
    "\n",
    "        for k in range(row_count):\n",
    "            temp_data[k, nominal_features[i]] = temp_dict[temp_data[k, nominal_features[i]]]\n",
    "    \n",
    "    if(inp == 1):\n",
    "        final_data = temp_data.astype(np.float)\n",
    "        return final_data\n",
    "    elif(inp == 2):\n",
    "        final_data = temp_data.astype(np.int)\n",
    "        return (final_data,main_mapping_dict)\n",
    "\n",
    "def binary_feature_divide(data, feature_index, feature_val):\n",
    "    left_list = []\n",
    "    right_list = []\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i, feature_index] <= feature_val:\n",
    "            left_list.append(i)\n",
    "        else:\n",
    "            right_list.append(i)\n",
    "\n",
    "    left = data[left_list,:]\n",
    "    right = data[right_list,:]\n",
    "    return left, right\n",
    "\n",
    "def calculate_gain(left, right):\n",
    "    # SLIDE 52 - CLASSIFICATION 1\n",
    "    C1_parent = list(left[:, -1]).count(0) + list(right[:, -1]).count(0)\n",
    "    C2_parent = list(left[:, -1]).count(1) + list(right[:, -1]).count(1)\n",
    "    \n",
    "    root_gini = 1 - (C1_parent / (C1_parent + C2_parent))**2 - (C2_parent / (C1_parent + C2_parent))**2\n",
    "\n",
    "    N1_left = list(left[:, -1]).count(0)\n",
    "    N2_left = list(left[:, -1]).count(1)\n",
    "    if (N1_left + N2_left) != 0:\n",
    "        gini_left = 1 - (N1_left / (N1_left + N2_left))**2 - (N2_left / (N1_left + N2_left))**2\n",
    "    else:\n",
    "        gini_left = 0\n",
    "\n",
    "    N1_right = list(right[:, -1]).count(0)\n",
    "    N2_right = list(right[:, -1]).count(1)\n",
    "    if (N1_right + N2_right) != 0:\n",
    "        gini_right = 1 - (N1_right / (N1_right + N2_right))**2 - (N2_right / (N1_right + N2_right))**2\n",
    "    else:\n",
    "        gini_right = 0\n",
    "\n",
    "    gini_children = ((N1_left + N2_left) / (C1_parent + C2_parent)) * gini_left + ((N1_right + N2_right) / (C1_parent + C2_parent)) * gini_right\n",
    "    gain = root_gini - gini_children\n",
    "    return gain\n",
    "\n",
    "def get_best_feature_divide(feature_values):\n",
    "    gain = 0\n",
    "    dict1 = {}\n",
    "    for row in range(feature_values.shape[0]):\n",
    "        for col in range(feature_values.shape[1] - 1):\n",
    "            left, right = binary_feature_divide(feature_values, col, feature_values[row, col])\n",
    "            \n",
    "            upd_gain = calculate_gain(left, right)\n",
    "            if upd_gain > gain:\n",
    "                feature_index = col\n",
    "                feature_val = feature_values[row, col]\n",
    "                gain = upd_gain\n",
    "                dict1 = {\"feature_index\": feature_index, \"feature_val\": feature_val, \"left\": left, \"right\": right}\n",
    "    #print(\"Gain = \", gain)\n",
    "    return dict1\n",
    "\n",
    "def terminal_node(node_values):\n",
    "    if list(node_values[:, -1]).count(0) >= list(node_values[:, -1]).count(1):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def create_treebranch(full_tree_dict, max_depth, curr_depth, min_size):\n",
    "\n",
    "    left = full_tree_dict[\"left\"]\n",
    "    right = full_tree_dict[\"right\"]\n",
    "\n",
    "    del(full_tree_dict[\"left\"]) # or pop\n",
    "    del(full_tree_dict[\"right\"]) # or pop\n",
    "    \n",
    "    # No feature values left to iterate through so we get the terminal node \n",
    "    if left.shape[0] == 0:\n",
    "        full_tree_dict[\"left\"] = full_tree_dict[\"right\"] = terminal_node(right)\n",
    "\n",
    "    if right.shape[0] == 0:\n",
    "        full_tree_dict[\"left\"] = full_tree_dict[\"right\"] = terminal_node(left)\n",
    "\n",
    "    if curr_depth >= max_depth:\n",
    "        full_tree_dict[\"left\"] = terminal_node(left)\n",
    "        full_tree_dict[\"right\"] = terminal_node(right)\n",
    "\n",
    "    if left.shape[0] <= min_size:\n",
    "        full_tree_dict[\"left\"] = terminal_node(left)\n",
    "    else:\n",
    "        if (len(np.unique(left[:, -1])) == 1):\n",
    "            full_tree_dict[\"left\"] = left[0, -1]\n",
    "        else:\n",
    "            full_tree_dict[\"left\"] = create_treebranch(get_best_feature_divide(left), max_depth, curr_depth+1, min_size)\n",
    "\n",
    "    if right.shape[0] <= min_size:\n",
    "        full_tree_dict[\"right\"] = terminal_node(right)\n",
    "    else:\n",
    "        if (len(np.unique(right[:, -1])) == 1):\n",
    "            full_tree_dict[\"right\"] = right[0, -1]\n",
    "        else:\n",
    "            full_tree_dict[\"right\"] = create_treebranch(get_best_feature_divide(right), max_depth, curr_depth+1, min_size)\n",
    "\n",
    "    return full_tree_dict\n",
    "\n",
    "def find_testing_data_class(test_record, full_tree_dict):\n",
    "    if test_record[full_tree_dict[\"feature_index\"]] < full_tree_dict[\"feature_val\"]:\n",
    "        if type(full_tree_dict[\"left\"]) != dict:\n",
    "            return full_tree_dict[\"left\"]\n",
    "        else:\n",
    "            return find_testing_data_class(test_record, full_tree_dict[\"left\"])            \n",
    "    else:\n",
    "        if type(full_tree_dict[\"right\"]) != dict:\n",
    "            return full_tree_dict[\"right\"]            \n",
    "        else:\n",
    "            return find_testing_data_class(test_record, full_tree_dict[\"right\"])\n",
    "\n",
    "def decision_tree(file_path,inp,max_depth,min_size):\n",
    "    dataset = preprocessing_dataset(file_path, inp)\n",
    "\n",
    "    tenfold_val = np.array_split(dataset, 10)\n",
    "\n",
    "    #k_main = get_fold_range(dataset.shape[0],10)\n",
    "\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    fmeasure_list = []\n",
    "    \n",
    "    for i in range(len(tenfold_val)):\n",
    "        testing_data = tenfold_val[i]\n",
    "        training_data = np.array([]).reshape(0, tenfold_val[0].shape[1])\n",
    "        for j in range(len(tenfold_val)):\n",
    "            if (i!=j):\n",
    "                 training_data = np.concatenate((training_data, tenfold_val[j]), axis=0)\n",
    "    \n",
    "    #for i in k_main:\n",
    "    #    \n",
    "    #    training_data = dataset[i[1]:]\n",
    "    #    testing_data = dataset[i[0]:i[1]]\n",
    "    #    \n",
    "        actual_label = []\n",
    "        for j in testing_data:\n",
    "            actual_label.append(j[-1])\n",
    "\n",
    "        full_tree_dict = get_best_feature_divide(training_data)\n",
    "        #max_depth = 100\n",
    "        #min_size = 10\n",
    "        curr_depth = 1\n",
    "        full_tree_dict = create_treebranch(full_tree_dict, max_depth, curr_depth, min_size)\n",
    "\n",
    "        prediction = []\n",
    "\n",
    "        for test_record in testing_data:\n",
    "            prediction.append(find_testing_data_class(test_record, full_tree_dict))\n",
    "\n",
    "        (a,b,c,d) = performance_calculation(prediction, actual_label)\n",
    "\n",
    "        accuracy = (a+d)/(a+b+c+d)\n",
    "        precision = a/(a+c)\n",
    "        recall = a/(a+b)\n",
    "        fmeasure = (2*a)/((2*a)+b+c)\n",
    "        accuracy_list.append(accuracy); precision_list.append(precision);\n",
    "        recall_list.append(recall); fmeasure_list.append(fmeasure);\n",
    "    \n",
    "    return(accuracy_list, precision_list, recall_list, fmeasure_list)\n",
    "        \n",
    "def performance_calculation(prediction, actual_label):\n",
    "    a = 0; b = 0; c = 0; d = 0;\n",
    "\n",
    "    for i in range(len(prediction)):\n",
    "        if actual_label[i] == 1 and prediction[i] == 1:\n",
    "            a += 1\n",
    "        elif actual_label[i] == 1 and prediction[i] == 0:\n",
    "            b += 1\n",
    "        elif actual_label[i] == 0 and prediction[i] == 1:\n",
    "            c += 1\n",
    "        elif actual_label[i] == 0 and prediction[i] == 0:\n",
    "            d += 1\n",
    "\n",
    "    return (a,b,c,d)\n",
    "\n",
    "def display_measures(acc, prec, rec, fm):\n",
    "    if(len(acc)==1):\n",
    "        print(\"Algorithm Measures\")\n",
    "        print(\"Accuracy -> \"+str(acc[0]))\n",
    "        print(\"Precision -> \"+str(prec[0]))\n",
    "        print(\"Recall -> \"+str(rec[0]))\n",
    "        print(\"F-Measure -> \"+str(fm[0]))\n",
    "    else:\n",
    "        avg_accuracy = 0; avg_precision = 0; avg_recall = 0; avg_fmeasure = 0;\n",
    "        for i in range(len(acc)):\n",
    "            print(\"----------------------------------------\")\n",
    "            print(\"Cross Validation Iteration -> \"+str(i+1))\n",
    "            print(\"Algorithm Measures\")\n",
    "            print(\"Accuracy -> \"+str(acc[i]))\n",
    "            print(\"Precision -> \"+str(prec[i]))\n",
    "            print(\"Recall -> \"+str(rec[i]))\n",
    "            print(\"F-Measure -> \"+str(fm[i]))\n",
    "\n",
    "            avg_accuracy += acc[i]; avg_precision += prec[i]; avg_recall += rec[i]; avg_fmeasure += fm[i];\n",
    "\n",
    "        print(\"----------------------------------------\")\n",
    "        print(\"Average Measures\")\n",
    "        print(\"Average Accuracy -> \"+str(avg_accuracy/len(acc)))\n",
    "        print(\"Average Precision -> \"+str(avg_precision/len(prec)))\n",
    "        print(\"Average Recall -> \"+str(avg_recall/len(rec)))\n",
    "        print(\"Average F-Measure -> \"+str(avg_fmeasure/len(fm)))\n",
    "\n",
    "def display_demo_result(main_dict, full_tree_dict):\n",
    "    for i in main_dict.keys():\n",
    "        print(\"Feature Index (Column): \"+str(i))\n",
    "        #print(\"Feature Values: \")\n",
    "        temp_dict = main_dict[i]\n",
    "        for j in temp_dict.keys():\n",
    "            print(\"Feature Value -> \"+color.BOLD+str(j)+color.END+\" is mapped to -> \"+color.BOLD+str(temp_dict[j])+color.END)\n",
    "        print()\n",
    "    print(full_tree_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN RUNNING OF CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Cross Validation Iteration -> 1\n",
      "Algorithm Measures\n",
      "Accuracy -> 0.9122807017543859\n",
      "Precision -> 0.8461538461538461\n",
      "Recall -> 0.9565217391304348\n",
      "F-Measure -> 0.8979591836734694\n",
      "----------------------------------------\n",
      "Cross Validation Iteration -> 2\n",
      "Algorithm Measures\n",
      "Accuracy -> 0.9122807017543859\n",
      "Precision -> 0.8\n",
      "Recall -> 0.9411764705882353\n",
      "F-Measure -> 0.8648648648648649\n",
      "----------------------------------------\n",
      "Cross Validation Iteration -> 3\n",
      "Algorithm Measures\n",
      "Accuracy -> 0.9824561403508771\n",
      "Precision -> 1.0\n",
      "Recall -> 0.9285714285714286\n",
      "F-Measure -> 0.9629629629629629\n",
      "----------------------------------------\n",
      "Cross Validation Iteration -> 4\n",
      "Algorithm Measures\n",
      "Accuracy -> 0.9298245614035088\n",
      "Precision -> 0.9473684210526315\n",
      "Recall -> 0.8571428571428571\n",
      "F-Measure -> 0.9\n",
      "----------------------------------------\n",
      "Cross Validation Iteration -> 5\n",
      "Algorithm Measures\n",
      "Accuracy -> 0.8771929824561403\n",
      "Precision -> 0.8421052631578947\n",
      "Recall -> 0.8\n",
      "F-Measure -> 0.8205128205128205\n",
      "----------------------------------------\n",
      "Cross Validation Iteration -> 6\n",
      "Algorithm Measures\n",
      "Accuracy -> 0.9824561403508771\n",
      "Precision -> 0.9642857142857143\n",
      "Recall -> 1.0\n",
      "F-Measure -> 0.9818181818181818\n",
      "----------------------------------------\n",
      "Cross Validation Iteration -> 7\n",
      "Algorithm Measures\n",
      "Accuracy -> 0.8596491228070176\n",
      "Precision -> 0.75\n",
      "Recall -> 0.9545454545454546\n",
      "F-Measure -> 0.84\n",
      "----------------------------------------\n",
      "Cross Validation Iteration -> 8\n",
      "Algorithm Measures\n",
      "Accuracy -> 0.9649122807017544\n",
      "Precision -> 0.9333333333333333\n",
      "Recall -> 0.9333333333333333\n",
      "F-Measure -> 0.9333333333333333\n",
      "----------------------------------------\n",
      "Cross Validation Iteration -> 9\n",
      "Algorithm Measures\n",
      "Accuracy -> 0.9122807017543859\n",
      "Precision -> 0.9333333333333333\n",
      "Recall -> 0.9032258064516129\n",
      "F-Measure -> 0.9180327868852459\n",
      "----------------------------------------\n",
      "Cross Validation Iteration -> 10\n",
      "Algorithm Measures\n",
      "Accuracy -> 0.8571428571428571\n",
      "Precision -> 0.7916666666666666\n",
      "Recall -> 0.8636363636363636\n",
      "F-Measure -> 0.8260869565217391\n",
      "----------------------------------------\n",
      "Average Measures\n",
      "Average Accuracy -> 0.919047619047619\n",
      "Average Precision -> 0.880824657798342\n",
      "Average Recall -> 0.913815345339972\n",
      "Average F-Measure -> 0.8945571090572617\n"
     ]
    }
   ],
   "source": [
    "if(inp==1):\n",
    "    #file_path = input(\"Please enter the file name: \") #'data1.txt'\n",
    "    #max_depth = int(input(\"Please enter Max Depth Value: \"))\n",
    "    #min_size = int(input(\"Please enter Min Size Value: \"))\n",
    "    (acc, prec, rec, fm) = decision_tree(file_path, inp, max_depth1, min_size1)\n",
    "    display_measures(acc, prec, rec, fm)\n",
    "else:\n",
    "    #file_path = input(\"Please enter the file name: \") #\"project3_dataset4.txt\"\n",
    "    (dataset,main_dict) = preprocessing_dataset(file_path, inp)\n",
    "\n",
    "    full_tree_dict = get_best_feature_divide(dataset)\n",
    "    max_depth = 100\n",
    "    min_size = 1\n",
    "    curr_depth = 1\n",
    "\n",
    "    full_tree_dict = create_treebranch(full_tree_dict, max_depth, curr_depth, min_size)\n",
    "    display_demo_result(main_dict, full_tree_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/10756427/loop-through-all-nested-dictionary-values\n",
    "def myprint(d,assa):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            print(str(assa)+str(k))\n",
    "            assa = str(assa)+\"---\"\n",
    "            myprint(v,assa)\n",
    "        else:\n",
    "            print(\"{0}{1} : {2}\".format(assa,k, v))\n",
    "assa1 = \"---\" \n",
    "if(inp==2):\n",
    "    myprint(full_tree_dict,assa1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
